import numpy as np
import scipy.sparse
import kmeans
import matplotlib.pyplot as plt
from scipy.spatial import distance
#Define the data directory (change if you place data elsewhere)
data_dir = "/rahul_extra/MachineLearning/Kaggle/hw4/data/" 

#Load the training ratings
A       = np.load(data_dir + "train.npy")
A.shape = (1,)
Xtrain  = A[0]

#Load the validation ratings
A       = np.load(data_dir + "validate.npy")
A.shape = (1,)
Xval    = A[0]

#Load the test ratings
A       = np.load(data_dir + "test.npy")
A.shape = (1,)
Xtest   = A[0]

#Load the user, item, and genre information
Users   = np.load(data_dir + "users.npy")
Items   = np.load(data_dir + "items.npy")
Genres  = np.load(data_dir + "genres.npy")


def train_model(k=2):

	#Train k-Means on the training data
	#k=2
	model = kmeans.kmeans(n_clusters=k)
	model.fit(Xtrain)

	#Predict back the training ratings and compute the RMSE
	XtrainHat = model.predict(Xtrain,Xtrain)
	tr= model.rmse(Xtrain,XtrainHat)

	#Predict the validation ratings and compute the RMSE
	XvalHat = model.predict(Xtrain,Xval)
	val= model.rmse(Xval,XvalHat)

	#Predict the test ratings and compute the RMSE
	XtestHat = model.predict(Xtrain,Xtest)
	te= model.rmse(Xtest,XtestHat)

	#Get the cluster assignments for the training data
	z = model.cluster(Xtrain)
	print(z) , len(z)

	#Get the clusters 
	centers = model.get_centers()
	print(centers)

	print("K=%d Errors: %.7f %.7f "%(k,tr,val))
	#return (tr,val)

def cal_vt(final_result):
	final_t = []
	final_v = []
	for i in range(len(final_result)):
	    print "Step", i 
	    t = []
	    val = []
	    for j in final_result[i]:
	        t.append(j[0])
	        val.append(j[1])
	    t.sort(reverse=True)
	    val.sort(reverse=True)
	    print "Training Set"
	    print "max => ",t[0]
	    print "min =>",t[-1]
	    print "avg =>", sum(t)/len(t)
	    final_t.append([t[0],t[-1],sum(t)/len(t)])

	    print "Validation Set"
	    print "max =>",val[0]
	    print "min =>",val[-1]
	    print "avg =>",sum(val)/len(val)
	    final_v.append([val[0],val[-1],sum(val)/len(val)])
	    print "-------------------------------------------------------"
	return final_t,final_v


def plot(maxv,minv,avg):
	plt.style.use('ggplot')
	x = [2,5,10,15,20,25]
	plt.plot(x,maxv,label='Max')
	plt.plot(x,minv,label='Min')
	plt.plot(x,avg,label='Avg')
	
	#ploting straingt line 
	local = [avg[0],avg[-1]]
	plt.plot([x[0],x[-1]], local)

	#calculate max distance by plotting straight line 
	maxd = 0
	pt1 = 0
	pt2 = 0
	for x in range(1,len(avg)):
		y = -0.01*x  + 1  #Equation of st line calculated for test set
		#y = 0.001*x + 1.034 #Equation for validation set
		a = np.array([x,avg[x-1]])
		b = np.array([x,y])
		#dist = distance.euclidean(a,b)
		dist = np.fabs(y - avg[x-1])
		print "distance is ",dist
		if maxd < dist:
			maxd = dist
			pt1 = a
			pt2 = b
			print "iterim max distance",maxd , pt1, pt2

	print "Max distance between points ", maxd 
	print "points are", pt1 ,pt2

	#plotting the maximum distance between the 2 points 
	plt.scatter(pt1[0],pt1[1],s=40)

	plt.title('Test Set RMSE Scores')
	plt.legend()
	plt.show()

'''
#rl is range list for the 'k' clusters. 
rl = [2,5,10,15,20,25]
final_result = []
for i in rl:
	iresult = []
	for j in range(0,10):
		print "Iteration =>",j
		result = train_model(i)
		iresult.append(result)
	final_result.append(iresult)

print "the final result is",final_result
'''
#for range K = 1,10
#final_result = [[(0.9966367263864635, 1.0366734384117333), (0.9966367263864635, 1.0366734384117333), (0.9966367263864635, 1.0366734384117333), (0.9966367263864635, 1.0366734384117333), (0.9966367263864635, 1.0366734384117333), (0.9966367263864635, 1.0366734384117333), (0.9966367263864635, 1.0366734384117333), (0.9966367263864635, 1.0366734384117333), (0.9966367263864635, 1.0366734384117333), (0.9966367263864635, 1.0366734384117333)], [(0.93781913881324708, 1.0132798285866869), (0.93834411554672204, 1.0096441848442321), (0.95089475197066475, 1.0160223159086577), (0.93802489087358476, 1.0106513916603592), (0.93831861316784759, 1.0092057449475178), (0.93803975636622039, 1.0075230788297789), (0.93781703086725154, 1.0106781356464085), (0.93802204503872399, 1.0121972923611087), (0.95191936441519198, 1.0192909430479236), (0.93803981187492691, 1.0100384656294255)], [(0.91649168469501163, 1.0116056166508591), (0.91811654362614004, 1.004096688713308), (0.92453581499963744, 1.0202344340339256), (0.9195075763056938, 1.0130868217664188), (0.9221869496084476, 1.0148566672798387), (0.91466002547768332, 1.0003056897782787), (0.91975214634982105, 1.0164530139907726), (0.92105390352425442, 1.0206794934961325), (0.91923514504777926, 1.0064055047355376), (0.92255670341193174, 1.0055706501262807)], [(0.90974186427761106, 1.012527282845459), (0.89939877048676209, 1.0191111414152791), (0.90560941266789274, 1.0179305400772909), (0.90986713583050627, 1.0132422941267123), (0.90642660710188583, 1.0147675256501527), (0.908496851463508, 1.0205994409015382), (0.91459798464615294, 1.022751452135291), (0.90625720296550971, 1.0185996722375665), (0.90717159738263808, 1.0175335332653397), (0.90706067713604388, 1.0283351161115819)], [(0.89601793192325285, 1.0285691552203029), (0.89784189625999522, 1.0168100617634181), (0.90257961067292292, 1.0281341312266086), (0.90391655749712618, 1.0297157221817907), (0.91137582746817014, 1.0283165478490977), (0.90316367508806172, 1.0400336879453362), (0.9007983711650499, 1.0175652817466883), (0.89874098428548554, 1.0193980588940332), (0.89439035632508312, 1.0211900998228725), (0.89288703823300009, 1.0147031214202362)], [(0.89370086862942022, 1.0283184928613462), (0.89144546439300953, 1.0207163731692472), (0.88654297723196374, 1.0324019982221639), (0.89158563425423287, 1.0275971589772326), (0.89410170309545456, 1.0246226747885805), (0.89573986883886747, 1.0198532975058812), (0.89323638743140921, 1.0319056223519485), (0.89799245014047824, 1.037288783281596), (0.89770149295951029, 1.031302207579468), (0.89191789683954026, 1.0287211469453483)], [(0.88446010953691812, 1.0416477841207203), (0.88560574640397571, 1.0293563050051655), (0.88205755159670951, 1.0311496233135233), (0.88606234902292336, 1.0370753882388832), (0.88493975758692001, 1.0386633627685311), (0.89209451686496599, 1.0364685616792133), (0.88644315254843198, 1.02481771405157), (0.88696220911745327, 1.0259034093637462), (0.88462434443095306, 1.0328602640407365), (0.89046850550149792, 1.0386091254562813)], [(0.88967162927982835, 1.0391189003267858), (0.88753790812784661, 1.0357701806915156), (0.87888678074197746, 1.0335978833038115), (0.8809592043560911, 1.0481153696094494), (0.877702330476409, 1.0348681657941976), (0.8796320069520257, 1.0412206130163983), (0.87905002181999936, 1.042026303279348), (0.874925742752105, 1.0299670503181155), (0.87963606896505175, 1.0425902464198937), (0.88321181230062196, 1.0465185125675067)], [(0.87167306700260028, 1.0408078143152233), (0.87777180524300413, 1.044166988174156), (0.86959676709027212, 1.0403286255078126), (0.88159318735034164, 1.0421027415594299), (0.88101155023464772, 1.0527056824191441), (0.88115318639743268, 1.0358523090819214), (0.87873982607378354, 1.0443715162051861), (0.88330149290218762, 1.0489316822467178), (0.87327317367057156, 1.0362054035664803), (0.8815117818512761, 1.0456551248016031)], [(0.87117797369100436, 1.0393463345029115), (0.88093909583188534, 1.0454356622448466), (0.87866007152991243, 1.0539443015875234), (0.86403793547101904, 1.0434387656304664), (0.86948368583597568, 1.0537110453905336), (0.86606490760054755, 1.0444605049837843), (0.86839851953138025, 1.0468130430116376), (0.87326552635388477, 1.0377500631394523), (0.87014777330542459, 1.0398035275540636), (0.86669327748946046, 1.0493158748722728)]]

'''
#For range K = [2,5,10,15,20,25]
final_result = [[(0.93790631203168395, 1.0104183826319102), (0.93846147768963495, 1.0109912263054313), (0.93780248718573544, 1.0122828325889313), (0.93745872221005366, 1.0101435989091674), (0.93820476900941885, 1.011176775559566), (0.93791956177807667, 1.0111536959725653), (0.93776653858083914, 1.0100153168918649), (0.93875216550147045, 1.0068032130337508), (0.93756554229453826, 1.0108100053122393), (0.937719670537978, 1.0125600558776846)], [(0.89477242963465498, 1.017174327169621), (0.89293589707356225, 1.0115154993884232), (0.89497785615755032, 1.0215936457203145), (0.89739417198602911, 1.0162613952788129), (0.89418484305391222, 1.0049520716637685), (0.90292554027818805, 1.0281642071622681), (0.89533939860861012, 1.024825983624458), (0.89447048899689885, 1.0198787572637904), (0.90412688249766227, 1.0261318446658623), (0.89481456535265658, 1.0251856781103064)], [(0.87409259643901382, 1.051983478847192), (0.86891834961717007, 1.0517207701875049), (0.87214805653371419, 1.0469164826843349), (0.87720020233511931, 1.0598323540260839), (0.8702769350698969, 1.0512641840412769), (0.87336135263187797, 1.0436599840510683), (0.87576392502451617, 1.0491653351434287), (0.87671995524055779, 1.0525263384607555), (0.86792357196666203, 1.0327568550746731), (0.87844746428983245, 1.0532709931553283)], [(0.84655192616868047, 1.0599641800886159), (0.85145615285524057, 1.0639996078690108), (0.85478534138621809, 1.0706850450833469), (0.85584219166859643, 1.0625423618197403), (0.85408938036874527, 1.0635787642609165), (0.85359336005680564, 1.0624603590053798), (0.85303031780410588, 1.0617320235034515), (0.85749083776201074, 1.0777345293316634), (0.85535878268872922, 1.0838801774724349), (0.85324797429585431, 1.0560967171449929)], [(0.83953360583759529, 1.0776224971699926), (0.83960714338341447, 1.0645494503624715), (0.84364529094758101, 1.0766124807477064), (0.83903378674492712, 1.0644538146977276), (0.84633322807756417, 1.0776440978767681), (0.84317092136919314, 1.0792510477607513), (0.84771964375644437, 1.0837919748313933), (0.842105206761109, 1.0696100538940034), (0.84457791092076828, 1.0808592030280004), (0.84707041770431857, 1.0746189751024315)], [(0.82757621172920348, 1.0768421855578458), (0.82215924107396143, 1.0732837855609398), (0.82545118968339781, 1.0846150794869303), (0.83067862369886181, 1.0750134727293843), (0.83055181202596406, 1.0911540138394398), (0.82503448431808912, 1.0842302246557423), (0.83570347715677862, 1.077161486412439), (0.82182795656470009, 1.0911404118824699), (0.8224380439207285, 1.0731189101162939), (0.82873237069930306, 1.0784218823202556)]]


final_t,final_v = cal_vt(final_result)

max_t = [ i[0] for i in final_t]
min_t = [ i[1] for i in final_t]
avg = [i[2] for i in final_t]

plot(max_t, min_t, avg)
'''
train_model(5)


#Takes Dictionary of k,v pairs which contains
# <occupation,count>
def gen_piechart(u):
	ocp = {}
	for i in u:
		ocp[i[3]] = ocp.get(i[3],0) + 1 
	labels = []
	values = []
	for k,v in ocp.items():
		labels.append(k)
		values.append(v)
	plt.axis('equal')
	plt.pie(values,labels=labels,autopct="%1.1f%%")
	plt.title("Occupation based pie chart")
	plt.show()

def zipcode_pie(u):
	zc = {}
	for i in u:
		zc[i[4][0]] = zc.get(i[4][0],0) + 1
	print "length of zipcode dict",len(zc) , zc
	labels = []
	values = []
	for k,v in zc.items():
		labels.append(k)
		values.append(v)
	plt.axis('equal')
	plt.pie(values,labels=labels,autopct="%1.1f%%")
	plt.title("Zipcode based on regions")
	plt.show()

'''
Converting sparse matrix to dense matrix in here
data = sp.load('train.npy')[()]
dt = data.todense()
cr = dt[z==0] for Cluster K = 0 
'''
def user_ratings(cr):
	ratings = []
	avgr = {}
	for i in range(cr.shape[1]): #columns is the number of ratings
		val = float(sum(cr[:,i]).tolist()[0][0])
		ratings.append(val)
	for i in range(len(ratings)):
		avgr[i] = ratings[i]/len(cr)
	return avgr




